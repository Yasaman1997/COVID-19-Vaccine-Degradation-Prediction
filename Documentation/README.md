# OpenVaccine: COVID-19 mRNA Vaccine Degradation Prediction - Documentation

## Relevant content:
- [Building Seq2Seq LSTM with Luong Attention in Keras for Time Series Forecasting](https://levelup.gitconnected.com/building-seq2seq-lstm-with-luong-attention-in-keras-for-time-series-forecasting-1ee00958decb)
- [A ten-minute introduction to sequence-to-sequence learning in Keras](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html)
- [Simple Keras Transformer Model](https://medium.com/@max_garber/simple-keras-transformer-model-74724a83bb83)
- [Transformer model for language understanding](https://www.tensorflow.org/tutorials/text/transformer)
- [Content]()

## GitHub:
- [Git repository]()

## Papers:
- [ON THE RELATIONSHIP BETWEEN SELF-ATTENTION AND CONVOLUTIONAL LAYERS](https://openreview.net/pdf?id=HJlnC1rKPB)

## Videos:
- [Protein function prediction by neural networks - Cambridge ML Summit â€˜19](https://www.youtube.com/watch?v=x-35bDrKfHA)

## Kernels:
- [OpenVaccine: Simple GRU Model](https://www.kaggle.com/xhlulu/openvaccine-simple-gru-model)

## Discussions:
- [Understanding my baseline GRU model](https://www.kaggle.com/c/stanford-covid-vaccine/discussion/182303)
- [A gentle introduction to the world of DNA, mRNA and the mechanics of the Open Covid vaccine in plain English](https://www.kaggle.com/c/stanford-covid-vaccine/discussion/182320)
- [RNA visualization](https://www.kaggle.com/c/stanford-covid-vaccine/discussion/182177)
 
## Insights:
- ### Positive Insights
- ### Negative Insights
